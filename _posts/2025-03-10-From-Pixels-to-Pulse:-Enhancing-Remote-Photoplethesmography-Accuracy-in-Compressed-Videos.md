## From Pixels to Pulse: Enhancing Remote Photoplethysmography Accuracy in Compressed Videos

![cover image](/images/poster3.png)

Here's the project I won First Place in Engineering in the Synopsys Science Fair for.

Remote photoplethysmography (rPPG) is a camera-based contactless method to measure physiological signals such as heart rate by analyzing subtle changes in skin color related to blood flow. While often undetectable to the human eye, these small variations in the color of RGB pixels can be detected from high quality video. This technology has massive potential for telemedicine.  However, scaling this technology for widespread use poses challenges as video compression algorithms, often needed in real world scenarios, can obscure the image details and introduce noise, making precise measurement of physiological signals difficult. The goal of this project was to address the challenge of lossy compression by combining video restoration algorithms with an existing pulse extraction model. To do this, I trained PhysNet, a deep learning model that uses a spatio-temporal network (3DCNN), on the publicly available UBFC-rPPG dataset at different levels of compression (using H.264 codec) to get the baseline measurements. Then, I evaluated the effect of introducing denoising techniques such as non-local means in the preprocessing step. My experiments showed that as the compression ratio increased, MAE, MAPE, and RMSE also increased. Adding a denoising module in the preprocessing step to mitigate compression artifacts improved all the metrics for highly compressed videos. The MAPE was reduced by ~2.2% for compression ratio 100:1 and by ~4.4% for 150:1, indicating that this approach could be valuable in making the technology more accessible.
